---
title: "lab_report_knapsack"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{lab_report_knapsack}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(Khwarizmi)
```

# Introduction

In this lab report, we will explore and evaluate the performance of different algorithms used to solve the knapsack problem, a well-known combinatorial optimization problem. Understanding the performance of these methods in handling large data sets will help in determining their efficiency in solving real-world problems.

The knapsack problem involves selecting items, each with a specific weight and value, to place in a knapsack of limited capacity. The objective is to maximize the total value of the selected items without exceeding the knapsackâ€™s weight limit. Given its NP-complete nature, the problem becomes increasingly challenging as the number of items grows, making it an ideal case for testing algorithmic performance.

# Knapsack data

To test the efficiency of the algorithms, we first generate a synthetic dataset representing the items that can be placed in the knapsack:

```{r}
suppressWarnings(RNGversion(min(as.character(getRversion()),"3.5.3")))

set.seed(42, kind = "Mersenne-Twister", normal.kind = "Inversion")
n <- 2000
knapsack_objects <-
data.frame(
w=sample(1:4000, size = n, replace = TRUE),
v=runif(n = n, 0, 10000)
)
```

# Brute Force Search

The brute force method is the simplest and most intuitive way to solve the knapsack problem. It involves evaluating every possible combination of items to determine the one that provides the maximum value without exceeding the weight limit. The `system.time()` function is used to measure the execution time of the brute force algorithm, and the results of this approach are shown below.

```{r}
system.time(bfk <- brute_force_knapsack(x = knapsack_objects[1:16,], W = 2000))
```

# Dynamic Programming

Now, we will analyze the performance of the dynamic programming algorithm, which efficiently solves the knapsack problem by breaking it down into smaller subproblems. The results of this approach are shown below.

```{r}
system.time(bfk <- knapsack_dynamic(x = knapsack_objects[1:16,], W = 2000))
```

# Greedy Heuristic

The greedy heuristic approach offers a fast, although potentially suboptimal, solution by making the locally optimal choice at each step. This approach is significantly faster than the other two:

```{r}
# Generate a larger data frame first
set.seed(42, kind = "Mersenne-Twister", normal.kind = "Inversion")
n <- 1000000
knapsack_objects2 <-
data.frame(
w=sample(1:4000, size = n, replace = TRUE),
v=runif(n = n, 0, 10000)
)

system.time(bfk <- greedy_knapsack(x = knapsack_objects2[1:1000000,], W = 2000))

```

When compared directly with other algorithms, the greedy approach performs better:

```{r}
system.time(bfk <- greedy_knapsack(x = knapsack_objects[1:16,], W = 2000))
```

## Reasons Why a Greedy Algorithm Might Yield a Better Solution

The greedy algorithm can yield optimal solutions when item value-to-weight ratios align well with the knapsack's capacity. For example, selecting lightweight, high-value items results in a high total value. If items have similar weights and values, the algorithm avoids missing optimal combinations, as adding lighter items won't trigger weight limits.

Despite occasionally achieving optimal solutions, the greedy algorithm remains categorized as such because it selects items based solely on the highest value-to-weight ratio, ignoring broader implications. This approach relies on making the best local choice, assuming it will lead to a global optimum, which holds true for specific structured problems. While it may not guarantee optimal solutions for all configurations, its decision-making process is inherently greedy.

